{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "Here I will import all the libraries that are required for this project. I will be using `pandas` library to read the dataset and `pickle` library to store the trained models. \n",
    "\n",
    "For this project I will be using `Naive Bias` model, so I will also import it by using sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Used to hide the warnings from pandas library while replacing a value in a df copy. \n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore the data\n",
    "Now here I will load the dataset and we can see we have four columns in the dataframe:\n",
    "- `Description`: This the feature column, it contains all the descriptions for categories.\n",
    "- `Level_1`: First level of categories.\n",
    "- `Level_2`: Second level of categories.\n",
    "- `Level_3`: Third level of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Level_1</th>\n",
       "      <th>Level_2</th>\n",
       "      <th>Level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gerb cap help keep littl on head cov warm day ...</td>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>D06E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tut ballet anym leap foxy fash ruffl tul toddl...</td>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>D06E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>easy keep feel warm cozy inf toddl girl hoody ...</td>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10644</th>\n",
       "      <td>term 10 issu on year subscriptionyo sav 75 cov...</td>\n",
       "      <td>90A8B052</td>\n",
       "      <td>C719A</td>\n",
       "      <td>A0E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10645</th>\n",
       "      <td>term 12 issu on year subscriptionyo sav 86 cov...</td>\n",
       "      <td>90A8B052</td>\n",
       "      <td>C719A</td>\n",
       "      <td>A0E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10646</th>\n",
       "      <td>term 9 issu on year subscriptionyo sav 64 cov ...</td>\n",
       "      <td>90A8B052</td>\n",
       "      <td>C719A</td>\n",
       "      <td>A0E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10647</th>\n",
       "      <td>term 26 issu on year subscriptionyo sav 54 cov...</td>\n",
       "      <td>90A8B052</td>\n",
       "      <td>C719A</td>\n",
       "      <td>A0E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10648</th>\n",
       "      <td>term 12 issu on year subscriptionyo sav 60 cov...</td>\n",
       "      <td>90A8B052</td>\n",
       "      <td>C719A</td>\n",
       "      <td>A0E2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10649 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Description   Level_1 Level_2  \\\n",
       "0      gerb cap help keep littl on head cov warm day ...  09BF5150   C7E19   \n",
       "1      newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6   \n",
       "2      tut ballet anym leap foxy fash ruffl tul toddl...  09BF5150   C7E19   \n",
       "3      newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6   \n",
       "4      easy keep feel warm cozy inf toddl girl hoody ...  2CEC27F1   ADAD6   \n",
       "...                                                  ...       ...     ...   \n",
       "10644  term 10 issu on year subscriptionyo sav 75 cov...  90A8B052   C719A   \n",
       "10645  term 12 issu on year subscriptionyo sav 86 cov...  90A8B052   C719A   \n",
       "10646  term 9 issu on year subscriptionyo sav 64 cov ...  90A8B052   C719A   \n",
       "10647  term 26 issu on year subscriptionyo sav 54 cov...  90A8B052   C719A   \n",
       "10648  term 12 issu on year subscriptionyo sav 60 cov...  90A8B052   C719A   \n",
       "\n",
       "      Level_3  \n",
       "0        D06E  \n",
       "1        98CF  \n",
       "2        D06E  \n",
       "3        98CF  \n",
       "4        98CF  \n",
       "...       ...  \n",
       "10644    A0E2  \n",
       "10645    A0E2  \n",
       "10646    A0E2  \n",
       "10647    A0E2  \n",
       "10648    A0E2  \n",
       "\n",
       "[10649 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"product-cat-dataset.csv\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will use the `describe` method of pandas library. This method is used for calculating some statistical data like percentile, mean and std of the numerical values of the DataFrame, it analyzes both numeric and object data types. In our dataframe we don't have numerical data so this will just give us some small details about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Level_1</th>\n",
       "      <th>Level_2</th>\n",
       "      <th>Level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10637</td>\n",
       "      <td>10649</td>\n",
       "      <td>10649</td>\n",
       "      <td>10649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9677</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>glory gorg col fing complet outfit express moo...</td>\n",
       "      <td>B092BA29</td>\n",
       "      <td>2D5A3</td>\n",
       "      <td>28A7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>24</td>\n",
       "      <td>900</td>\n",
       "      <td>797</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Description   Level_1 Level_2  \\\n",
       "count                                               10637     10649   10649   \n",
       "unique                                               9677        15      39   \n",
       "top     glory gorg col fing complet outfit express moo...  B092BA29   2D5A3   \n",
       "freq                                                   24       900     797   \n",
       "\n",
       "       Level_3  \n",
       "count    10649  \n",
       "unique      43  \n",
       "top       28A7  \n",
       "freq       797  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing Data\n",
    "Now I will check for missing values in the dataframe. I will use `isnull()` method. This method will return a copy of dataframe with boolean values. If their is any missing value in the dataset then that cell will be filled by `True`. And now after that I will use `sum()` method, this will calculate how many values of each column we have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description    12\n",
       "Level_1         0\n",
       "Level_2         0\n",
       "Level_3         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if data has missing values in the Description column\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see, `Description` is the only column which have **12** missing entries, so now I will delete all those rows from the dataframe. In the cell give below I will clean the dataset from missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_index = dataframe[dataframe['Description'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after cleaning we will again check if we have missing values in the dataset or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description    False\n",
       "Level_1        False\n",
       "Level_2        False\n",
       "Level_3        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with missing values\n",
    "dataframe.drop(dataframe.index[missing_values_index], inplace=True)\n",
    "dataframe.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Classes where the number of instances is < 10\n",
    "In this part I will check the number of instances for each class Level and if any class has less than **10 instances**, I will delete it from the dataframe. \n",
    "\n",
    "So for implementing this, I will create a helper function which will take dataframe and class level as a parameter and then in that function I will delete those classes which have less then 10 instances and return a filtered dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df, class_level):\n",
    "    class_freq = df[class_level].value_counts().to_dict()\n",
    "    delete_flag = False\n",
    "    classes_to_delete = []\n",
    "    \n",
    "    # Iterating over each class frequency\n",
    "    for key, value in class_freq.items():\n",
    "        if value < 10:\n",
    "            delete_flag = True\n",
    "            print(\"Deleting Class {} with {} number of instances.\".format(key, value))\n",
    "            classes_to_delete.append(key)\n",
    "\n",
    "    # Selecting a copy of dataframe in which those classes will not be added which we have to delete\n",
    "    df = df.loc[~df[class_level].isin(classes_to_delete)]\n",
    "    \n",
    "    if delete_flag == False:\n",
    "        print(\"No class Found with less than 10 instances\")\n",
    "    else:\n",
    "        print(\"Class Frequencies after filtering dataframe\")        \n",
    "        \n",
    "    updated_class_freq = df[class_level].value_counts().to_dict()\n",
    "\n",
    "    for key, value in updated_class_freq.items():\n",
    "        print(\"Class {} having {} number of instances.\".format(key, value))\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No class Found with less than 10 instances\n",
      "Class B092BA29 having 900 number of instances.\n",
      "Class 35E04739 having 896 number of instances.\n",
      "Class AAC8EE56 having 890 number of instances.\n",
      "Class 57164AC1 having 877 number of instances.\n",
      "Class 2CEC27F1 having 859 number of instances.\n",
      "Class EFEF723B having 800 number of instances.\n",
      "Class 09BF5150 having 799 number of instances.\n",
      "Class 69286F45 having 797 number of instances.\n",
      "Class 96F95EEC having 587 number of instances.\n",
      "Class 3E1E0D78 having 579 number of instances.\n",
      "Class 4C3D8686 having 574 number of instances.\n",
      "Class 4513C920 having 558 number of instances.\n",
      "Class 014303D1 having 511 number of instances.\n",
      "Class 90A8B052 having 506 number of instances.\n",
      "Class D410C91A having 504 number of instances.\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_1 \n",
    "dataframe = filter_dataframe(dataframe, class_level=\"Level_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Class 80D5B with 6 number of instances.\n",
      "Deleting Class A6301 with 1 number of instances.\n",
      "Deleting Class C66C5 with 1 number of instances.\n",
      "Class Frequencies after filtering dataframe\n",
      "Class 2D5A3 having 797 number of instances.\n",
      "Class ACD06 having 504 number of instances.\n",
      "Class C719A having 482 number of instances.\n",
      "Class 9D9EE having 462 number of instances.\n",
      "Class 5A8AB having 450 number of instances.\n",
      "Class 375FE having 450 number of instances.\n",
      "Class BAE8A having 449 number of instances.\n",
      "Class B2DB4 having 449 number of instances.\n",
      "Class CB803 having 448 number of instances.\n",
      "Class 9B69F having 447 number of instances.\n",
      "Class 74974 having 446 number of instances.\n",
      "Class 914A1 having 443 number of instances.\n",
      "Class 390F1 having 441 number of instances.\n",
      "Class 94728 having 440 number of instances.\n",
      "Class C7E19 having 429 number of instances.\n",
      "Class 7B638 having 420 number of instances.\n",
      "Class A04D3 having 411 number of instances.\n",
      "Class ADAD6 having 410 number of instances.\n",
      "Class F4055 having 363 number of instances.\n",
      "Class 7AED7 having 282 number of instances.\n",
      "Class 02FA0 having 264 number of instances.\n",
      "Class 77F62 having 229 number of instances.\n",
      "Class 36080 having 176 number of instances.\n",
      "Class 223B2 having 128 number of instances.\n",
      "Class E6162 having 117 number of instances.\n",
      "Class 5E038 having 115 number of instances.\n",
      "Class E69F5 having 109 number of instances.\n",
      "Class D5531 having 88 number of instances.\n",
      "Class 31FED having 86 number of instances.\n",
      "Class F824F having 72 number of instances.\n",
      "Class 262E7 having 63 number of instances.\n",
      "Class 915D4 having 47 number of instances.\n",
      "Class AF6B9 having 36 number of instances.\n",
      "Class 6C6B1 having 36 number of instances.\n",
      "Class 08960 having 24 number of instances.\n",
      "Class 0864A having 16 number of instances.\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_2\n",
    "dataframe = filter_dataframe(dataframe, class_level=\"Level_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Class DE3D with 1 number of instances.\n",
      "Deleting Class CF52 with 1 number of instances.\n",
      "Class Frequencies after filtering dataframe\n",
      "Class 28A7 having 797 number of instances.\n",
      "Class 33D1 having 504 number of instances.\n",
      "Class A0E2 having 482 number of instances.\n",
      "Class 05A0 having 462 number of instances.\n",
      "Class 1F61 having 450 number of instances.\n",
      "Class AA6B having 450 number of instances.\n",
      "Class 21DA having 449 number of instances.\n",
      "Class 627D having 448 number of instances.\n",
      "Class 2ABA having 448 number of instances.\n",
      "Class 80C4 having 447 number of instances.\n",
      "Class 62E8 having 446 number of instances.\n",
      "Class D97D having 443 number of instances.\n",
      "Class 6856 having 441 number of instances.\n",
      "Class 5912 having 439 number of instances.\n",
      "Class D06E having 429 number of instances.\n",
      "Class 0F8B having 420 number of instances.\n",
      "Class C5B4 having 411 number of instances.\n",
      "Class 98CF having 410 number of instances.\n",
      "Class 6539 having 282 number of instances.\n",
      "Class 078B having 264 number of instances.\n",
      "Class 5AE1 having 229 number of instances.\n",
      "Class 1F75 having 199 number of instances.\n",
      "Class C563 having 176 number of instances.\n",
      "Class 7C00 having 164 number of instances.\n",
      "Class F213 having 128 number of instances.\n",
      "Class 2E14 having 117 number of instances.\n",
      "Class 6BE5 having 115 number of instances.\n",
      "Class DDD5 having 109 number of instances.\n",
      "Class 6253 having 88 number of instances.\n",
      "Class 7288 having 72 number of instances.\n",
      "Class 29B3 having 63 number of instances.\n",
      "Class 3DD3 having 53 number of instances.\n",
      "Class A2FA having 47 number of instances.\n",
      "Class A104 having 36 number of instances.\n",
      "Class 3AAD having 36 number of instances.\n",
      "Class 215F having 33 number of instances.\n",
      "Class 1000 having 24 number of instances.\n",
      "Class 96B8 having 16 number of instances.\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_3\n",
    "dataframe = filter_dataframe(dataframe, class_level=\"Level_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's write a Function to Prepare Text\n",
    "We will apply it to our DataFrame later on\n",
    "\n",
    "* This function receives a text string and performs the following:\n",
    "* Convert text to lower case\n",
    "* Remove punctuation marks\n",
    "* Apply stemming using the popular Snowball or Porter Stemmer (optional)\n",
    "* Apply NGram Tokenisation\n",
    "* Return the tokenised text as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for fetching n-grams\n",
    "def get_n_gram(words_list, n=1):\n",
    "    n_grams = []\n",
    "    \n",
    "    for i in range(len(words_list)):\n",
    "        gram = []\n",
    "        j = i\n",
    "        for _ in range(n):\n",
    "            gram.append(words_list[j])\n",
    "            j += 1\n",
    "            \n",
    "            if j >= len(words_list):\n",
    "                break\n",
    "                \n",
    "        if len(gram) == n:\n",
    "            n_grams.append(gram)    \n",
    "    \n",
    "    return n_grams\n",
    "\n",
    "\n",
    "def process_text(text, n = 1):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Convert text to lower case and remove all punctuation\n",
    "    2. Optionally apply stemming\n",
    "    3. Apply Ngram Tokenisation\n",
    "    4. Returns the tokenised text as a list\n",
    "    \"\"\"\n",
    "    # write steps here\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z ]+', '',text)\n",
    "    words = text.split(\" \")\n",
    "    stem_words = []\n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    for word in words:\n",
    "        stem_words.append(porter.stem(word))\n",
    "    \n",
    "    n_grams = get_n_gram(stem_words, n)\n",
    "    tokenised = []\n",
    "    \n",
    "    for gram in n_grams:\n",
    "        sentence = \" \".join(gram)\n",
    "        tokenised.append(sentence)\n",
    "    \n",
    "    return tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['here were test',\n",
       " 'were test the',\n",
       " 'test the processtext',\n",
       " 'the processtext function',\n",
       " 'processtext function result',\n",
       " 'function result are',\n",
       " 'result are as',\n",
       " 'are as follow']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example function call\n",
    "process_text(\"Here we're testing the process_text function, results are as follows:\", n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['here were test',\n",
       " 'were test the',\n",
       " 'test the processtext',\n",
       " 'the processtext function',\n",
       " 'processtext function result',\n",
       " 'function result are',\n",
       " 'result are as',\n",
       " 'are as follow']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results should look like this:\n",
    "['here were test',\n",
    " 'were test the',\n",
    " 'test the processtext',\n",
    " 'the processtext function',\n",
    " 'processtext function result',\n",
    " 'function result are',\n",
    " 'result are as',\n",
    " 'are as follow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's apply TF-IDF to extract features from plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10627x154666 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 336704 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Might take a while...\n",
    "# Here you apply the process_text function to the Description column of the data\n",
    "# Then you pass the results to the bag of words tranformer\n",
    "# See here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "dataframe[\"Description\"] = dataframe[\"Description\"].values.astype('unicode')\n",
    "descriptions = dataframe[\"Description\"].to_numpy()\n",
    "labels = dataframe.drop([\"Description\"], axis=1)\n",
    "proccessed_features = []\n",
    "\n",
    "i = 0\n",
    "for description in descriptions:\n",
    "    proccessed_features.append(process_text(description, n = 2))\n",
    "    \n",
    "# Because we have lowercase the words and created n-grams so we will provide those 2 parameters\n",
    "vectorizer = CountVectorizer(lowercase=False, analyzer=lambda x:x)\n",
    "count_vectorizer = vectorizer.fit_transform(proccessed_features)\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use .transform on our Bag-of-Words (bow) transformed object and transform the entire DataFrame of text file contents. Let's go ahead and check out how the bag-of-words counts for the entire corpus in a large, sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10627x154666 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 336704 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After that you pass the result of the previous step to sklearn's TfidfTransformer\n",
    "# which will convert them into a feature matrix\n",
    "# See here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "\n",
    "tfidftransformer = TfidfTransformer()\n",
    "tfidf_vectorizer = tfidftransformer.fit_transform(count_vectorizer)\n",
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resulting matrix is in sparse format, we can transform it into dense\n",
    "# Code prepared for you so you can see what results look like\n",
    "text_tfidf = pd.DataFrame(tfidf_vectorizer[:10].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>154656</th>\n",
       "      <th>154657</th>\n",
       "      <th>154658</th>\n",
       "      <th>154659</th>\n",
       "      <th>154660</th>\n",
       "      <th>154661</th>\n",
       "      <th>154662</th>\n",
       "      <th>154663</th>\n",
       "      <th>154664</th>\n",
       "      <th>154665</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 154666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       1       2       3       4       5       6       7       8       \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   9       ...  154656  154657  154658  154659  154660  154661  154662  \\\n",
       "0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   154663  154664  154665  \n",
       "0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 154666 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an example result, the matrix will contain lots of zero values, that is expected\n",
    "# Some values will be non-zero\n",
    "text_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the Data is Ready for Classifier Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train and Test sets\n",
    "Now here I will split the dataset into training and testing sets. I will use **20%** data for testing and **80%** for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vectorizer, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>154656</th>\n",
       "      <th>154657</th>\n",
       "      <th>154658</th>\n",
       "      <th>154659</th>\n",
       "      <th>154660</th>\n",
       "      <th>154661</th>\n",
       "      <th>154662</th>\n",
       "      <th>154663</th>\n",
       "      <th>154664</th>\n",
       "      <th>154665</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 154666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0       1       2       3       4       5       6       7       8       \\\n",
       "0  0.063976     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1  0.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2  0.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3  0.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4  0.053572     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   9       ...  154656  154657  154658  154659  154660  154661  154662  \\\n",
       "0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   154663  154664  154665  \n",
       "0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 154666 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train.toarray())\n",
    "X_test = pd.DataFrame(X_test.toarray())\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to reset index in each dataframe (depends on you how you do things)\n",
    "# done for you to make it clearer\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to take classes as separate columns (depends on you how you do things)\n",
    "class1training = y_train['Level_1'].astype(str)\n",
    "class1testing = y_test['Level_1'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training for the three levels\n",
    "I will be using `Naive Bias Classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "classifier.fit(X_train, class1training)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Acurracy of Level 1 model: 85.61%\n",
      "It too 0 minutes and 12 seconds to train the model.\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.score(X_test, class1testing)\n",
    "mins, sec = divmod(stop - start, 60)\n",
    "\n",
    "print(\"Testing Acurracy of Level 1 model: {}%\".format(round((accuracy * 100) , 2)))\n",
    "print(\"It too {} minutes and {} seconds to train the model.\".format(round(mins), round(sec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Level 1 model\n",
    "path = \"./Models\"\n",
    "file_name = \"Level1_model.pickle\"\n",
    "save_path = os.path.join(path, file_name)\n",
    "\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will create some helper functions which will help through the training process of Level 2 and Level 3 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_classes_from_next_level(data, previous_level, model_class, current_level):\n",
    "    \"\"\"\n",
    "    Takes in data with category level information, then return the unique classes for required level.\n",
    "    \"\"\"\n",
    "    temp = data[data[previous_level] == model_class]\n",
    "    return temp[current_level].unique()\n",
    "\n",
    "def filter_data(X_train, y_train, current_level, current_classes):\n",
    "    \"\"\"\n",
    "    Takes in data with category level information, \n",
    "    then return filtered dataframe according to a class in a specific level.\n",
    "    \"\"\"\n",
    "    filtered_X_dataframes = []\n",
    "    filtered_y_dataframes = []\n",
    "\n",
    "    for cl in current_classes:\n",
    "        train_data_indexes = y_train[y_train[current_level] == cl].index.tolist()\n",
    "        #features\n",
    "        filtered_X_dataframes.append(X_train.iloc[train_data_indexes])        \n",
    "        #labels\n",
    "        filtered_y_dataframes.append(y_train.iloc[train_data_indexes])\n",
    "\n",
    "        \n",
    "    if len(current_classes) == 1:\n",
    "        updated_X_dataframe, updated_y_dataframe = update_filtered_data_one_class(X_train, y_train,\\\n",
    "                                                                              len(train_data_indexes), \\\n",
    "                                                                              current_classes[0],\\\n",
    "                                                                              current_level)\n",
    "        \n",
    "        filtered_X_dataframes.append(updated_X_dataframe)\n",
    "        filtered_y_dataframes.append(updated_y_dataframe)\n",
    "        \n",
    "    return pd.concat(filtered_X_dataframes), pd.concat(filtered_y_dataframes)\n",
    "\n",
    "\n",
    "# #############################################\n",
    "def update_filtered_data_one_class(X_train, y_train, available_data_length, current_class, current_level):\n",
    "    \"\"\"\n",
    "    Takes in data with only one class, then selects a random sample of same size\n",
    "    and assign another class to make an even dataset to train the model for that class.\n",
    "    \"\"\"\n",
    "    data_indexes = y_train[y_train[current_level] != current_class].index.tolist()\n",
    "    indexes_to_select = random.sample(data_indexes, available_data_length)\n",
    "    \n",
    "    selected_X_train = X_train.iloc[indexes_to_select]\n",
    "    selected_y_train = y_train.iloc[indexes_to_select]\n",
    "    replaced_class = selected_y_train[current_level].unique()[0]\n",
    "    selected_y_train.loc[:, [current_level]] = replaced_class\n",
    "    \n",
    "    return selected_X_train, selected_y_train\n",
    "\n",
    "# #########################################\n",
    "def train_models(X_train, y_train, model_class, previous_level, current_level):\n",
    "    \"\"\"\n",
    "    Takes in data with category level information, then train and save the models.\n",
    "    \"\"\"\n",
    "    unique_classes = get_unique_classes_from_next_level(y_train, previous_level, model_class, current_level)\n",
    "    filtered_X_train, filtered_y_train = filter_data(X_train, y_train, current_level, unique_classes)\n",
    "\n",
    "    # Create and save models for level 2\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(filtered_X_train, filtered_y_train[current_level])\n",
    "    accuracy = classifier.score(filtered_X_train, filtered_y_train[current_level])\n",
    "    \n",
    "    # Path\n",
    "    path = \"./Models\"\n",
    "    file_name = model_class + \".pickle\"\n",
    " \n",
    "    save_path = os.path.join(path, current_level, file_name)\n",
    "    \n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "\n",
    "    print(\"Trained and saved Model for Class {}\".format(model_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved Model for Class 09BF5150\n",
      "Trained and saved Model for Class 2CEC27F1\n",
      "Trained and saved Model for Class AAC8EE56\n",
      "Trained and saved Model for Class 4C3D8686\n",
      "Trained and saved Model for Class 69286F45\n",
      "Trained and saved Model for Class 57164AC1\n",
      "Trained and saved Model for Class 4513C920\n",
      "Trained and saved Model for Class 35E04739\n",
      "Trained and saved Model for Class EFEF723B\n",
      "Trained and saved Model for Class 96F95EEC\n",
      "Trained and saved Model for Class 014303D1\n",
      "Trained and saved Model for Class 90A8B052\n",
      "Trained and saved Model for Class B092BA29\n",
      "Trained and saved Model for Class 3E1E0D78\n",
      "Trained and saved Model for Class D410C91A\n",
      "15 Total Models Trained and Saved for Level 2\n"
     ]
    }
   ],
   "source": [
    "level1_classes = dataframe[\"Level_1\"].unique()\n",
    "for cl in level1_classes:\n",
    "    train_models(X_train, y_train, cl, \"Level_1\", \"Level_2\")\n",
    "\n",
    "print(\"{} Total Models Trained and Saved for Level 2\".format(len(level1_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved Model for Class C7E19\n",
      "Trained and saved Model for Class ADAD6\n",
      "Trained and saved Model for Class 914A1\n",
      "Trained and saved Model for Class 74974\n",
      "Trained and saved Model for Class 2D5A3\n",
      "Trained and saved Model for Class 9B69F\n",
      "Trained and saved Model for Class 7B638\n",
      "Trained and saved Model for Class F4055\n",
      "Trained and saved Model for Class 0864A\n",
      "Trained and saved Model for Class F824F\n",
      "Trained and saved Model for Class B2DB4\n",
      "Trained and saved Model for Class 02FA0\n",
      "Trained and saved Model for Class D5531\n",
      "Trained and saved Model for Class CB803\n",
      "Trained and saved Model for Class BAE8A\n",
      "Trained and saved Model for Class 31FED\n",
      "Trained and saved Model for Class E69F5\n",
      "Trained and saved Model for Class 390F1\n",
      "Trained and saved Model for Class 94728\n",
      "Trained and saved Model for Class 36080\n",
      "Trained and saved Model for Class 77F62\n",
      "Trained and saved Model for Class A04D3\n",
      "Trained and saved Model for Class 7AED7\n",
      "Trained and saved Model for Class 915D4\n",
      "Trained and saved Model for Class 6C6B1\n",
      "Trained and saved Model for Class 5E038\n",
      "Trained and saved Model for Class 262E7\n",
      "Trained and saved Model for Class AF6B9\n",
      "Trained and saved Model for Class C719A\n",
      "Trained and saved Model for Class 375FE\n",
      "Trained and saved Model for Class 5A8AB\n",
      "Trained and saved Model for Class 08960\n",
      "Trained and saved Model for Class 9D9EE\n",
      "Trained and saved Model for Class E6162\n",
      "Trained and saved Model for Class ACD06\n",
      "Trained and saved Model for Class 223B2\n",
      "36 Total Models Trained and Saved for Level 3\n"
     ]
    }
   ],
   "source": [
    "level2_classes = dataframe[\"Level_2\"].unique()\n",
    "for cl in level2_classes:\n",
    "    train_models(X_train, y_train, cl, \"Level_2\", \"Level_3\")\n",
    "\n",
    "print(\"{} Total Models Trained and Saved for Level 3\".format(len(level2_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty Dataframe with column names only (depends on you how you do things)\n",
    "results = pd.DataFrame(columns=['Level1_Pred', 'Level2_Pred', 'Level3_Pred'])\n",
    "\n",
    "## Here we reload the saved models and use them to predict the levels\n",
    "# load model for level 1 (done for you)\n",
    "with open('./Models/Level1_model.pickle', 'rb') as nb:\n",
    "    level1_model = pickle.load(nb)\n",
    "\n",
    "## loop through the test data, predict level 1, then based on that predict level 2\n",
    "## and based on level 2 predict level 3 (you need to load saved models accordingly)\n",
    "dir_path = \"./Models\"\n",
    "\n",
    "for index, test_data in X_test.iterrows():\n",
    "    # Because we are predicting categories for a single sample, so we will reshape it first.    \n",
    "    data = np.array(test_data).reshape(1, -1)\n",
    "    # Level 1 prediction\n",
    "    level1_pred = level1_model.predict(data)    \n",
    "    level1_pred_class = level1_pred[0] + \".pickle\"\n",
    "    \n",
    "    model_path = os.path.join(dir_path, \"Level_2\", level1_pred_class)\n",
    "    with open(model_path, 'rb') as nb:\n",
    "        level2_model = pickle.load(nb)\n",
    "    # Level 2 preidction\n",
    "    level2_pred = level2_model.predict(data)    \n",
    "    \n",
    "    level2_pred_class = level2_pred[0] + \".pickle\"\n",
    "    model_path = os.path.join(dir_path, \"Level_3\", level2_pred_class)\n",
    "    with open(model_path, 'rb') as nb:\n",
    "        level3_model = pickle.load(nb)\n",
    "    # Level 3 prediction\n",
    "    level3_pred = level3_model.predict(data)\n",
    "    \n",
    "    results.at[index, \"Level1_Pred\"] = level1_pred[0]\n",
    "    results.at[index, \"Level2_Pred\"] = level2_pred[0]\n",
    "    results.at[index, \"Level3_Pred\"] = level3_pred[0]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level1_Pred</th>\n",
       "      <th>Level2_Pred</th>\n",
       "      <th>Level3_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014303D1</td>\n",
       "      <td>77F62</td>\n",
       "      <td>5AE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09BF5150</td>\n",
       "      <td>915D4</td>\n",
       "      <td>A2FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>BAE8A</td>\n",
       "      <td>2ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57164AC1</td>\n",
       "      <td>94728</td>\n",
       "      <td>5912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57164AC1</td>\n",
       "      <td>94728</td>\n",
       "      <td>5912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>AAC8EE56</td>\n",
       "      <td>9B69F</td>\n",
       "      <td>80C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>AAC8EE56</td>\n",
       "      <td>9B69F</td>\n",
       "      <td>80C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>AAC8EE56</td>\n",
       "      <td>914A1</td>\n",
       "      <td>D97D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>ADAD6</td>\n",
       "      <td>98CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>014303D1</td>\n",
       "      <td>77F62</td>\n",
       "      <td>5AE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level1_Pred Level2_Pred Level3_Pred\n",
       "0       014303D1       77F62        5AE1\n",
       "1       09BF5150       915D4        A2FA\n",
       "2       2CEC27F1       BAE8A        2ABA\n",
       "3       57164AC1       94728        5912\n",
       "4       57164AC1       94728        5912\n",
       "...          ...         ...         ...\n",
       "1058    AAC8EE56       9B69F        80C4\n",
       "1059    AAC8EE56       9B69F        80C4\n",
       "1060    AAC8EE56       914A1        D97D\n",
       "1061    2CEC27F1       ADAD6        98CF\n",
       "1062    014303D1       77F62        5AE1\n",
       "\n",
       "[1063 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy on each level\n",
    "Now you have the predictions for each level (in the test data), and you also have the actual levels, you can compute the accurcay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Acurracy of Level 1 model: 85.61%\n"
     ]
    }
   ],
   "source": [
    "# Level 1 accuracy\n",
    "level1_accuracy = accuracy_score(y_test[\"Level_1\"], results[\"Level1_Pred\"])\n",
    "print(\"Testing Acurracy of Level 1 model: {}%\".format(round((level1_accuracy * 100) , 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Acurracy of Level 2 model: 78.17%\n"
     ]
    }
   ],
   "source": [
    "# Level 2 accuracy\n",
    "level2_accuracy = accuracy_score(y_test[\"Level_2\"], results[\"Level2_Pred\"])\n",
    "print(\"Testing Acurracy of Level 2 model: {}%\".format(round((level2_accuracy * 100) , 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Acurracy of Level 3 model: 76.76%\n"
     ]
    }
   ],
   "source": [
    "# Level 3 accuracy\n",
    "level3_accuracy = accuracy_score(y_test[\"Level_3\"], results[\"Level3_Pred\"])\n",
    "print(\"Testing Acurracy of Level 3 model: {}%\".format(round((level3_accuracy * 100) , 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
